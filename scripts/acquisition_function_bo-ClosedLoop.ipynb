{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959e41e2-276f-475a-92de-9e2d5701262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: /Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# This file costructs surrogate models for the input datasets\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Torch specific module imports\n",
    "import torch\n",
    "import gpytorch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# botorch specific modules\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Tick parameters\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "# User defined python classes and files\n",
    "import sys\n",
    "sys.path.insert(0, './feature_engineering/')\n",
    "\n",
    "import input_class \n",
    "import surrogate_model_inputs as model_input\n",
    "import utils_dataset as utilsd\n",
    "import surrogate_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2ecd3-441e-4f8f-afa9-508a1c825191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6e585d-a9be-4d75-a883-8bcb9f6f961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf, optimize_acqf_discrete\n",
    "\n",
    "bounds = torch.tensor([[-10.0], [12.0]])\n",
    "\n",
    "batch_size = 1\n",
    "num_restarts= 10 \n",
    "raw_samples = 512\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func, X_test, Y_test, model, likelihood):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate\"\"\"\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        choices=X_test,\n",
    "        q=batch_size,\n",
    "        max_batch_size=2048,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        unique=True\n",
    "    )\n",
    "    \n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    b = [1 if torch.all(X_test[i].eq(new_x)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "    b = torch.tensor(b).to(torch.int)\n",
    "    index = b.nonzero()[0][0]\n",
    "    if model_input.new_values_predict_from_model:\n",
    "        new_y_mean, new_y_var = surrogate_models.predict_surrogates(model, likelihood, new_x)\n",
    "        X_test_new = X_test[torch.arange(0, X_test.shape[0]) != index, ...]\n",
    "        Y_test_new = Y_test[..., torch.arange(0, Y_test.shape[1]) != index]\n",
    "        \n",
    "        return new_x, new_y_mean, new_y_var, index, X_test_new, Y_test_new\n",
    "    else:\n",
    "        new_y = torch.reshape(Y_test[0,index],(1,1))        \n",
    "        X_test_new = X_test[torch.arange(0, X_test.shape[0]) != index, ...]\n",
    "        Y_test_new = Y_test[..., torch.arange(0, Y_test.shape[1]) != index]\n",
    "        \n",
    "        return new_x, new_y, index, X_test_new, Y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c98148-3179-4a99-8455-ea6e6267ad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d0ea0c-2bb5-4c25-9829-fee13cc68486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created! /Users/maitreyeesharma/WORKSPACE/PostDoc/EngChem/MatDisc_ML/python_notebook_bo/../bo_output/debug_trial5/\n",
      "\n",
      " -------------------- Trial  1 of 5 --------------------\n",
      "Reading data for the input dataset type:  MPEA\n",
      "Reading data for the input dataset type:  MPEA\n",
      "\n",
      "Batch  1: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  2: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  3: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  4: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  5: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  6: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  7: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  8: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  9: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch 10: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)time = 8.69.\n",
      "\n",
      " -------------------- Trial  2 of 5 --------------------\n",
      "Reading data for the input dataset type:  MPEA\n",
      "Reading data for the input dataset type:  MPEA\n",
      "\n",
      "Batch  1: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  2: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  3: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  4: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  5: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  6: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  7: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  8: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  9: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch 10: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)time = 8.78.\n",
      "\n",
      " -------------------- Trial  3 of 5 --------------------\n",
      "Reading data for the input dataset type:  MPEA\n",
      "Reading data for the input dataset type:  MPEA\n",
      "\n",
      "Batch  1: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  2: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  3: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  4: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  5: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  6: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  7: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  8: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  9: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch 10: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)time = 10.85.\n",
      "\n",
      " -------------------- Trial  4 of 5 --------------------\n",
      "Reading data for the input dataset type:  MPEA\n",
      "Reading data for the input dataset type:  MPEA\n",
      "\n",
      "Batch  1: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  2: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  3: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  4: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  5: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  6: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  7: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  8: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  9: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch 10: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)time = 10.25.\n",
      "\n",
      " -------------------- Trial  5 of 5 --------------------\n",
      "Reading data for the input dataset type:  MPEA\n",
      "Reading data for the input dataset type:  MPEA\n",
      "\n",
      "Batch  1: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  2: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  3: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  4: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  5: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  6: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  7: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  8: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch  9: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)\n",
      "Batch 10: Observed, Best_value (GP-0, GP-Linear) =  ( 3.2)time = 10.42.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Create a new directory if it does not exist\n",
    "isExist = os.path.exists(model_input.output_folder)\n",
    "if not isExist:\n",
    "    os.makedirs(model_input.output_folder)\n",
    "    print(\"The new directory is created!\", model_input.output_folder)\n",
    "    \n",
    "# Copy input parameters file to output folder\n",
    "shutil.copy2('surrogate_model_inputs.py',model_input.output_folder)\n",
    "# Copy surrogate model file to output folder\n",
    "shutil.copy2('surrogate_models.py',model_input.output_folder)\n",
    "\n",
    "# BO Trials\n",
    "n_trials = model_input.n_trials\n",
    "n_update = model_input.n_update\n",
    "verbose = model_input.verbose\n",
    "\n",
    "test_size = model_input.test_size\n",
    "train_NN = model_input.train_NN\n",
    "saveModel_NN = model_input.saveModel_NN\n",
    "train_GP = model_input.train_GP\n",
    "predict_NN = model_input.predict_NN\n",
    "\n",
    "GP_0 = model_input.GP_0_BO\n",
    "GP_L = model_input.GP_L_BO\n",
    "GP_NN = model_input.GP_NN_BO\n",
    "\n",
    "num_nodes = model_input.num_nodes\n",
    "saveModel_filename = model_input.saveModel_filename\n",
    "    \n",
    "best_observed_all_ei0, best_observed_all_eiL, best_observed_all_eiNN = [], [], []\n",
    "newy_observed_all_ei0, newy_observed_all_eiL, newy_observed_all_eiNN = [], [], []\n",
    "newx_observed_all_ei0, newx_observed_all_eiL, newx_observed_all_eiNN = [], [], []\n",
    "newy_var_observed_all_ei0, newy_var_observed_all_eiL, newy_var_observed_all_eiNN = [], [], []\n",
    "index_observed_all_ei0, index_observed_all_eiL, index_observed_all_eiNN = [], [], []\n",
    "\n",
    "# Average over multiple trials\n",
    "for trial in range(1, n_trials + 1):\n",
    "    t0 = time.monotonic()\n",
    "    if model_input.random_seed == 'time':\n",
    "        random_seed = int(t0)\n",
    "    elif model_input.random_seed == 'iteration':\n",
    "        random_seed = trial\n",
    "        \n",
    "    print(f\"\\n -------------------- Trial {trial:>2} of {n_trials} --------------------\\n\", end=\"\")\n",
    "    best_observed0, best_observedL, best_observedNN = [], [], []\n",
    "    new_x_observed0, new_x_observedL, new_x_observedNN = [], [], []\n",
    "    new_y_observed0, new_y_observedL, new_y_observedNN = [], [], []\n",
    "    new_y_var_observed0, new_y_var_observedL, new_y_var_observedNN = [], [], []\n",
    "    index_observed0, index_observedL, index_observedNN = [], [], []\n",
    "    \n",
    "    # Getting initial data and fitting models with initial data\n",
    "    if model_input.standardize_data:\n",
    "        X_train, Y_train, Var_train, scalerX_transform, scalerY_transform, descriptors = utilsd.read_training_data(random_seed)\n",
    "        X_test, Y_test, Var_test = utilsd.read_test_data(random_seed, descriptors, scalerX_transform)       \n",
    "    else:\n",
    "        scalerX_transform=[]\n",
    "        X_train, Y_train, Var_train, descriptors = utilsd.read_training_data(random_seed)        \n",
    "        X_test, Y_test, Var_test = utilsd.read_test_data(random_seed,descriptors,scalerX_transform)\n",
    "\n",
    "    if model_input.train_NN:\n",
    "        surrogate_models.train_surrogate_NN(X_train, Y_train,saveModel_filename)\n",
    "    \n",
    "    # Finding best value in initial data\n",
    "    if model_input.maximization:\n",
    "        best_observed_value = Y_train.max()\n",
    "    else:\n",
    "        best_observed_value = Y_train.min()\n",
    "        \n",
    "    # Initialize data for training gp-0 and gp-l models\n",
    "    X_train0, Y_train0, X_test0, Y_test0 = X_train, Y_train, X_test, Y_test\n",
    "    X_trainL, Y_trainL, X_testL, Y_testL = X_train, Y_train, X_test, Y_test\n",
    "            \n",
    "    n_batch = 10 #Y_test.shape[1]\n",
    "    \n",
    "    # Initialize likelihood, GP model and acquisition function for the models\n",
    "    #--------------------------- GP-Linear ---------------------------#   \n",
    "    if GP_L:\n",
    "        likelihood_gpL = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model_gpL = surrogate_models.LinearGPModel(X_trainL, Y_trainL, likelihood_gpL)\n",
    "    \n",
    "        # AcqFunc_L = UpperConfidenceBound(model_gpL, beta=0.1)\n",
    "        AcqFunc_L = ExpectedImprovement(model=model_gpL, best_f=best_observed_value, maximize=model_input.maximization)  \n",
    "        best_observedL.append(best_observed_value.numpy())  # Appending to best_observed list for the given trial\n",
    "       \n",
    "    #--------------------------- GP-0 ---------------------------#\n",
    "    if GP_0:\n",
    "        likelihood_gp0 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model_gp0 = surrogate_models.ExactGPModel(X_train0, Y_train0, likelihood_gp0)           \n",
    "        # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "        AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_observed_value, maximize=model_input.maximization)\n",
    "        best_observed0.append(best_observed_value.numpy())  # Appending to best_observed list for the given trial\n",
    "         \n",
    "    #--------------------------- GP-NN ---------------------------#\n",
    "    if GP_NN:\n",
    "        likelihood_gpnn = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model_gpnn = surrogate_models.NN_Gaussian(X_trainNN, Y_trainNN, likelihood_gpnn, saveModel_filename,num_nodes)\n",
    "    \n",
    "        # AcqFunc_NN = UpperConfidenceBound(model_gpnn, beta=0.1)\n",
    "        AcqFunc_NN = ExpectedImprovement(model=model_gpnn, best_f=best_observed_valueNN, maximize=model_input.maximization)          \n",
    "        best_observedNN.append(best_observed_valueNN.numpy())  # Appending to best_observed list for the given trial\n",
    "    \n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, n_batch + 1):\n",
    "\n",
    "        if GP_L:\n",
    "            if ((iteration-1)%n_update==0):\n",
    "                # fit the models every 10 iterations  \n",
    "                model_gpL, likelihood_gpL = surrogate_models.train_surrogate_gpL(saveModel_filename, num_nodes, X_trainL, Y_trainL)\n",
    "\n",
    "            # optimize and get new observation using acquisition function\n",
    "            if model_input.new_values_predict_from_model:\n",
    "                new_xL, new_yL, new_yvar_L, index, X_test_newL, Y_test_newL = optimize_acqf_and_get_observation(AcqFunc_L, X_testL, Y_testL, model_gpL, likelihood_gpL)\n",
    "                \n",
    "                # Update remaining choices tensor\n",
    "                X_testL = X_test_newL\n",
    "                Y_testL = Y_test_newL\n",
    "    \n",
    "                # Update training points\n",
    "                X_trainL = torch.cat([X_trainL, new_xL])\n",
    "                Y_trainL = torch.cat([Y_trainL[0], new_yL])\n",
    "                new_y_var_observedL.append(new_yvar_L[0].numpy())\n",
    "\n",
    "            else:\n",
    "                new_xL, new_yL, index, X_test_newL, Y_test_newL = optimize_acqf_and_get_observation(AcqFunc_L, X_testL, Y_testL, model_gpL, likelihood_gpL)\n",
    "            \n",
    "                # Update remaining choices tensor\n",
    "                X_testL = X_test_newL\n",
    "                Y_testL = Y_test_newL\n",
    "    \n",
    "                # Update training points\n",
    "                X_trainL = torch.cat([X_trainL, new_xL])\n",
    "                Y_trainL = torch.cat([Y_trainL[0], new_yL[0]])\n",
    "\n",
    "            Y_trainL = torch.reshape(Y_trainL,(1,Y_trainL.shape[0]))        \n",
    "            new_xL_inv_transformed = scalerX_transform.inverse_transform(new_xL[0].numpy().reshape(1, -1), copy=None)\n",
    "            new_yL_inv_transformed = scalerY_transform.inverse_transform(new_yL[0].numpy().reshape(1, -1), copy=None)\n",
    "            b = [1 if torch.all(X_test[i].eq(new_xL)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "            b = torch.tensor(b).to(torch.int)\n",
    "            indexL = b.nonzero()[0][0]\n",
    "            \n",
    "            # update progress\n",
    "            if model_input.maximization:\n",
    "                best_value_eiL = Y_trainL.max()\n",
    "            elif not model_input.maximization:\n",
    "                best_value_eiL = Y_trainL.min()\n",
    "            best_observedL.append(best_value_eiL.numpy())\n",
    "            new_x_observedL.append(new_xL_inv_transformed[0])\n",
    "            index_observedL.append(indexL.numpy())\n",
    "            new_y_observedL.append(new_yL_inv_transformed[0][0])\n",
    "            \n",
    "            # AcqFunc_L = UpperConfidenceBound(model_gpL, beta=0.1) \n",
    "            AcqFunc_L = ExpectedImprovement(model=model_gpL, best_f=best_value_eiL, maximize=model_input.maximization) \n",
    "  \n",
    "        if GP_0:\n",
    "            if ((iteration-1)%n_update==0):\n",
    "                # fit the models every 10 iterations\n",
    "                model_gp0, likelihood_gp0 = surrogate_models.train_surrogate_gp0(saveModel_filename, num_nodes, X_train0, Y_train0)\n",
    "            \n",
    "            # optimize and get new observation using acquisition function\n",
    "            if model_input.new_values_predict_from_model:\n",
    "                new_x0, new_y0, new_yvar_0, index, X_test_new0, Y_test_new0 = optimize_acqf_and_get_observation(AcqFunc_0, X_test0, Y_test0, model_gp0, likelihood_gp0)\n",
    "                \n",
    "                # Update remaining choices tensor\n",
    "                X_test0 = X_test_new0\n",
    "                Y_test0 = Y_test_new0\n",
    "    \n",
    "                # Update training points\n",
    "                X_train0 = torch.cat([X_train0, new_x0])\n",
    "                Y_train0 = torch.cat([Y_train0[0], new_y0])\n",
    "                new_y_var_observed0.append(new_yvar_0[0].numpy())\n",
    "\n",
    "            else:                \n",
    "                new_x0, new_y0, index, X_test_new0, Y_test_new0 = optimize_acqf_and_get_observation(AcqFunc_0, X_test0, Y_test0, model_gp0, likelihood_gp0)\n",
    "                \n",
    "                # Update remaining choices tensor\n",
    "                X_test0 = X_test_new0\n",
    "                Y_test0 = Y_test_new0\n",
    "                # Update training points\n",
    "                X_train0 = torch.cat([X_train0, new_x0])\n",
    "                Y_train0 = torch.cat([Y_train0[0], new_y0[0]])\n",
    "\n",
    "            Y_train0 = torch.reshape(Y_train0,(1,Y_train0.shape[0]))\n",
    "            new_x0_inv_transformed = scalerX_transform.inverse_transform(new_x0[0].numpy().reshape(1, -1), copy=None)\n",
    "            new_y0_inv_transformed = scalerY_transform.inverse_transform(new_y0[0].numpy().reshape(1, -1), copy=None)\n",
    "            \n",
    "            b = [1 if torch.all(X_test[i].eq(new_x0)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "            b = torch.tensor(b).to(torch.int)\n",
    "            index0 = b.nonzero()[0][0]\n",
    "            \n",
    "            # update progress\n",
    "            if model_input.maximization:\n",
    "                best_value_ei0 = Y_train0.max()\n",
    "            elif not model_input.maximization:\n",
    "                best_value_ei0 = Y_train0.min()\n",
    "            best_observed0.append(best_value_ei0.numpy())\n",
    "            new_x_observed0.append(new_x0_inv_transformed[0])\n",
    "            index_observed0.append(index0.numpy())\n",
    "            new_y_observed0.append(new_y0_inv_transformed[0][0])\n",
    "\n",
    "            # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "            AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_value_ei0, maximize=model_input.maximization)\n",
    "      \n",
    "        if GP_NN:\n",
    "            if ((iteration-1)%n_update==0):\n",
    "                # fit the models every n_update iterations\n",
    "                # surrogate_models.train_surrogate_NN(X_trainNN, Y_trainNN, saveModel_filename)\n",
    "                model_gpnn, likelihood_gpnn = surrogate_models.train_surrogate_gpnn(saveModel_filename, test_size, num_nodes, X_trainNN, Y_trainNN)\n",
    "            # optimize and get new observation using acquisition function\n",
    "            new_xNN, new_yNN, index, X_test_newNN, Y_test_newNN = optimize_acqf_and_get_observation(AcqFunc_NN, X_testNN, Y_testNN, model_gpNN, likelihood_gpNN)\n",
    "            \n",
    "            # Update remaining choices tensor\n",
    "            X_testNN = X_test_newNN\n",
    "            Y_testNN = Y_test_newNN\n",
    "\n",
    "            # Update training points\n",
    "            X_trainNN = torch.cat([X_trainNN, new_xNN])\n",
    "            Y_trainNN = torch.cat([Y_trainNN[0], new_yNN[0]])\n",
    "            Y_trainNN = torch.reshape(Y_trainNN,(1,Y_trainNN.shape[0]))        \n",
    "\n",
    "            # update progress\n",
    "            if model_input.maximization:\n",
    "                best_value_eiNN = Y_trainNN.max() \n",
    "                # print(new_yNN) # To check: why is the max value getting updated in next iteration?\n",
    "            elif not model_input.maximization:\n",
    "                best_value_eiNN = Y_trainNN.min() \n",
    "            best_observedNN.append(best_value_eiNN.numpy())\n",
    "            new_x_observedNN.append(new_xNN.numpy())\n",
    "            index_observedL.append(indexNN.numpy())\n",
    "            new_y_observedNN.append(new_yNN[0].numpy())\n",
    "            \n",
    "            AcqFunc_NN = ExpectedImprovement(model=model_gpnn, best_f=best_value_eiNN, maximize=model_input.maximization) \n",
    "        \n",
    "        if verbose:\n",
    "            # print(\n",
    "            #     f\"\\nBatch {iteration:>2}: best_value (GP-0, GP-Linear, GP-NN) = \",\n",
    "            #     f\"({best_value_ei0:>4.2f}, {best_value_eiL:>4.2f}, {best_value_eiNN:>4.2f})\",\n",
    "            #     end=\"\",)            \n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: Observed, Best_value (GP-0, GP-Linear) = \",\n",
    "                f\"({best_value_eiL:>4.2})\",\n",
    "                end=\"\",)            \n",
    "\n",
    "    t1 = time.monotonic()\n",
    "    \n",
    "    print(f\"time = {t1-t0:>4.2f}.\")\n",
    "    # Appending to common list of best and new observed values, with number of rows equal to number of trials\n",
    "    if GP_0:\n",
    "        best_observed_all_ei0.append(best_observed0)\n",
    "        newy_observed_all_ei0.append(new_y_observed0)\n",
    "        newx_observed_all_ei0.append(new_x_observed0)\n",
    "        newy_var_observed_all_ei0.append(new_y_var_observed0)\n",
    "        index_observed_all_ei0.append(index_observed0)\n",
    "\n",
    "    if GP_L:\n",
    "        best_observed_all_eiL.append(best_observedL)\n",
    "        newy_observed_all_eiL.append(new_y_observedL)\n",
    "        newx_observed_all_eiL.append(new_x_observedL)\n",
    "        newy_var_observed_all_eiL.append(new_y_var_observedL)\n",
    "        index_observed_all_eiL.append(index_observedL)\n",
    "        \n",
    "    if GP_NN:\n",
    "        best_observed_all_eiNN.append(best_observedNN)\n",
    "        newy_observed_all_eiNN.append(new_y_observedNN)\n",
    "        newx_observed_all_eiNN.append(new_x_observedNN)\n",
    "        newy_var_observed_all_eiNN.append(new_y_var_observedNN)\n",
    "        index_observed_all_eiNN.append(index_observedNN)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65504b32-9156-4f00-977a-44732b6dd603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bac94f-9d2a-4684-9a8d-19fe0d39a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveOutput = True\n",
    "\n",
    "if SaveOutput:\n",
    "    if GP_0:\n",
    "        best_observed_df_gp0 = pd.DataFrame()\n",
    "        newy_observed_df_gp0 = pd.DataFrame()\n",
    "        newy_var_observed_df_gp0 = pd.DataFrame()\n",
    "        newx_observed_df_gp0 = pd.DataFrame()\n",
    "        index_observed_df_gp0 = pd.DataFrame()\n",
    "        \n",
    "        for trial in range(1, n_trials + 1):\n",
    "            gp0_column_name = 'gp0_trial' + str(trial)\n",
    "            best_observed_df_gp0[gp0_column_name] = best_observed_all_ei0[trial-1][0:n_batch]\n",
    "            newy_observed_df_gp0[gp0_column_name] = newy_observed_all_ei0[trial-1][0:n_batch]            \n",
    "            newy_var_observed_df_gp0[gp0_column_name] = newy_var_observed_all_ei0[trial-1][0:n_batch]                        \n",
    "            newx_observed_df_gp0[gp0_column_name] = newx_observed_all_ei0[trial-1][0:n_batch]\n",
    "            index_observed_df_gp0[gp0_column_name] = index_observed_all_ei0[trial-1][0:n_batch]\n",
    "            \n",
    "        best_observed_df_gp0.to_csv(model_input.output_folder+'gp0_best.csv',index=False)\n",
    "        newy_observed_df_gp0.to_csv(model_input.output_folder+'gp0_newTarget.csv',index=False)\n",
    "        newy_var_observed_df_gp0.to_csv(model_input.output_folder+'gp0_newTarget_variance.csv',index=False)\n",
    "        newx_observed_df_gp0.to_csv(model_input.output_folder+'gp0_newRecommendation.csv',index=False)\n",
    "        index_observed_df_gp0.to_csv(model_input.output_folder+'gp0_IndexRecommendation.csv',index=False)\n",
    "        \n",
    "    if GP_L:\n",
    "        best_observed_df_gpL = pd.DataFrame()\n",
    "        newy_observed_df_gpL = pd.DataFrame()\n",
    "        newy_var_observed_df_gpL = pd.DataFrame()\n",
    "        newx_observed_df_gpL = pd.DataFrame()\n",
    "        index_observed_df_gpL = pd.DataFrame()\n",
    "        \n",
    "        for trial in range(1, n_trials + 1):\n",
    "            gpL_column_name = 'gpL_trial' + str(trial) \n",
    "            best_observed_df_gpL[gpL_column_name] = best_observed_all_eiL[trial-1][0:n_batch]\n",
    "            newy_observed_df_gpL[gpL_column_name] = newy_observed_all_eiL[trial-1][0:n_batch]            \n",
    "            newy_var_observed_df_gpL[gpL_column_name] = newy_var_observed_all_eiL[trial-1][0:n_batch]                        \n",
    "            newx_observed_df_gpL[gpL_column_name] = newx_observed_all_eiL[trial-1][0:n_batch]   \n",
    "            index_observed_df_gpL[gpL_column_name] = index_observed_all_eiL[trial-1][0:n_batch]\n",
    "        \n",
    "        best_observed_df_gpL.to_csv(model_input.output_folder+'gpL_best.csv',index=False)\n",
    "        newy_observed_df_gpL.to_csv(model_input.output_folder+'gpL_newTarget.csv',index=False)\n",
    "        newy_var_observed_df_gpL.to_csv(model_input.output_folder+'gpL_newTarget_variance.csv',index=False)\n",
    "        newx_observed_df_gpL.to_csv(model_input.output_folder+'gpL_newRecommendation.csv',index=False)\n",
    "        index_observed_df_gpL.to_csv(model_input.output_folder+'gpL_IndexRecommendation.csv',index=False)\n",
    "        \n",
    "    if GP_NN:\n",
    "        best_observed_df_gpNN = pd.DataFrame()\n",
    "        newy_observed_df_gp0 = pd.DataFrame()\n",
    "        newy_var_observed_df_gp0 = pd.DataFrame()\n",
    "        newx_observed_df_gp0 = pd.DataFrame()\n",
    "        index_observed_df_gpNN = pd.DataFrame()\n",
    "        \n",
    "        for trial in range(1, n_trials + 1): \n",
    "            gpNN_column_name = 'gpNN_trial' + str(trial) \n",
    "            best_observed_df_gpNN[gpNN_column_name] = best_observed_all_eiNN[trial-1][0:200]\n",
    "        best_observed_df_gpNN.to_csv(model_input.output_folder+'gpNN.csv',index=False)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae3ed8-e6e8-4490-888b-ca8fd4492b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e56431-fc5d-4182-8c41-d756a697fcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
