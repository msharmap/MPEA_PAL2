{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a4625d-d723-41f1-9868-f94220c3bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: /Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/maitreyeesharma/opt/anaconda3/envs/torch/lib/python3.11/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# This file costructs surrogate models for the input datasets\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Torch specific module imports\n",
    "import torch\n",
    "import gpytorch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# botorch specific modules\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Tick parameters\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "# User defined python classes and files\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "\n",
    "import input_class \n",
    "import code_verification as verification\n",
    "import surrogate_model_inputs as model_input\n",
    "import utils_dataset as utilsd\n",
    "import surrogate_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de54b1c-0d62-4971-8fae-21a18a3fa15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data for the input dataset type:  MPEA\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1\n",
    "# Reading the input test datafile\n",
    "with open(model_input.run_folder+'inputs_testing.json', \"r\") as f:\n",
    "    input_dict = json.load(f)\n",
    "\n",
    "input_type = input_dict['InputType']\n",
    "input_path = input_dict['InputPath']\n",
    "input_file = input_dict['InputFile']\n",
    "add_target_noise = input_dict['AddTargetNoise']\n",
    "\n",
    "input = input_class.inputs(input_type=input_type,\n",
    "                           input_path=input_path,\n",
    "                           input_file=input_file,\n",
    "                           add_target_noise=add_target_noise,\n",
    "                           composition_MPEA = True)\n",
    "\n",
    "XX, YY, descriptors = input.read_inputs(model_input.verbose)\n",
    "\n",
    "# Reading the BO output files\n",
    "if model_input.GP_0_BO:\n",
    "    best_observed_df_gp0 = pd.read_csv(model_input.output_folder+'gp0_best.csv')\n",
    "    newy_observed_df_gp0 = pd.read_csv(model_input.output_folder+'gp0_newTarget.csv')\n",
    "    newy_var_observed_df_gp0 = pd.read_csv(model_input.output_folder+'gp0_newTarget_variance.csv')\n",
    "    newx_observed_df_gp0 = pd.read_csv(model_input.output_folder+'gp0_newRecommendation.csv')\n",
    "    index_observed_df_gp0 = pd.read_csv(model_input.output_folder+'gp0_IndexRecommendation.csv')\n",
    "    \n",
    "if model_input.GP_L_BO:\n",
    "    best_observed_df_gpL = pd.read_csv(model_input.output_folder+'gpL_best.csv')\n",
    "    newy_observed_df_gpL = pd.read_csv(model_input.output_folder+'gpL_newTarget.csv')\n",
    "    newy_var_observed_df_gpL = pd.read_csv(model_input.output_folder+'gpL_newTarget_variance.csv')\n",
    "    newx_observed_df_gpL = pd.read_csv(model_input.output_folder+'gpL_newRecommendation.csv')\n",
    "    index_observed_df_gpL = pd.read_csv(model_input.output_folder+'gpL_IndexRecommendation.csv')\n",
    "    \n",
    "if model_input.GP_NN_BO:\n",
    "    best_observed_df_gpNN = pd.read_csv(model_input.output_folder+'gpNN_best.csv')\n",
    "    newy_observed_df_gpNN = pd.read_csv(model_input.output_folder+'gpNN_newTarget.csv')\n",
    "    newy_var_observed_df_gpNN = pd.read_csv(model_input.output_folder+'gpNN_newTarget_variance.csv')\n",
    "    newx_observed_df_gpNN = pd.read_csv(model_input.output_folder+'gpNN_newRecommendation.csv')\n",
    "    index_observed_df_gpNN = pd.read_csv(model_input.output_folder+'gpNN_IndexRecommendation.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7abd5d-4d2a-41aa-8c32-9fd82bf13190",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = XX.loc[index_observed_df_gpL['gpL_trial1']].reset_index()\n",
    "target = newy_observed_df_gpL[:]\n",
    "comp['Hardness Value'] = target.mean(axis=1)\n",
    "comp = comp.sort_values(by=['Hardness Value'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ae3429-4320-4182-9656-17824d5878a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.to_csv(model_input.output_folder+'Recommendations.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79615e21-6f7c-4c59-bb06-c9e609e8e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round1_reco = pd.read_csv(model_input.output_folder+'../mpea_hv_forEddie_0.01p_FirstPass_Aug/Recommendations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f8b71-f702-4ac5-9ca3-728caa8e23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_shortlist = comp[:][0:20]\n",
    "Round1_reco_shortlist = Round1_reco[:][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666feba-cc60-4026-b4cb-e9eca25d8ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
